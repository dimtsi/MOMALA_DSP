{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch / PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import timeit\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "label_types = ['white_blood_cell','debris','malariae', 'falciparum', 'ovale']\n",
    "\n",
    "def create_df(dir_name):\n",
    "    directory = dir_name\n",
    "    augmented_df = pd.DataFrame(columns=['image','class'])\n",
    "\n",
    "    idx = 0\n",
    "    for image_name in os.listdir(directory):\n",
    "        if 'white_blood_cell' in image_name:\n",
    "            label_type = 'white_blood_cell'\n",
    "        else:\n",
    "            label_type = image_name.split('_')[0]\n",
    "\n",
    "        class_number = label_types.index(label_type)\n",
    "        augmented_df.loc[idx] = [image_name,class_number]\n",
    "        idx += 1\n",
    "    return augmented_df\n",
    "\n",
    "train_labels_df = create_df('./split_gamma_0.5/train')\n",
    "train_labels_df_sobel = create_df('./splitSobel/train')\n",
    "\n",
    "test_labels_df = create_df('./split/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_types.index('ovale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels_df = pd.read_csv('original_train.csv')\n",
    "# test_labels_df = pd.read_csv('original_test.csv')\n",
    "\n",
    "train_PIL_images = [] \n",
    "test_PIL_images = [] \n",
    "\n",
    "train_PIL_images_sobel = []\n",
    "train_labels_sobel = []\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "for filename in train_labels_df['image'].values: ##to keep mapping with classes\n",
    "    train_PIL_images.append(Image.open('split_gamma_0.5/train/'+filename).copy())\n",
    "    train_labels.append(train_labels_df.loc[train_labels_df['image'] == filename, 'class'].iloc[0])\n",
    "    \n",
    "for filename in train_labels_df_sobel['image'].values: ##to keep mapping with classes\n",
    "    train_PIL_images_sobel.append(Image.open('splitSobel/train/'+filename).copy())\n",
    "    train_labels_sobel.append(train_labels_df_sobel.loc[train_labels_df_sobel['image'] == filename, 'class'].iloc[0])\n",
    "    \n",
    "for filename in test_labels_df['image'].values: ##to keep mapping with classes\n",
    "    test_PIL_images.append(Image.open('split/test/'+filename).copy())\n",
    "    test_labels.append(test_labels_df.loc[test_labels_df['image'] == filename, 'class'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11724"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "X_train.extend(train_PIL_images)\n",
    "X_train.extend(train_PIL_images_sobel)\n",
    "\n",
    "Y_train = []\n",
    "Y_train.extend(train_labels)\n",
    "Y_train.extend(train_labels_sobel)\n",
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    220\n",
       "0     83\n",
       "1     11\n",
       "2      8\n",
       "4      7\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset/DataLoader for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Custom Datasets that obtain lists of PIL Images \n",
    "and labels as input\n",
    "\"\"\"\n",
    "\n",
    "class ListsTrainDataset(Dataset):\n",
    "    def __init__(self, list_of_images, list_of_labels, transform=None):\n",
    "        \n",
    "        self.data = list_of_images\n",
    "        self.labels = np.asarray(list_of_labels).reshape(-1,1)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image = self.data[index]\n",
    "        single_image_label = self.labels[index]\n",
    "        # Transform image to tensor\n",
    "        if self.transform is not None:\n",
    "            img_as_tensor = self.transform(single_image)\n",
    "        # Return image and the label\n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "\n",
    "class ListsTestDataset(Dataset):\n",
    "    def __init__(self, list_of_images, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            height (int): image height\n",
    "            width (int): image width\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.data = list_of_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image = self.data[index]\n",
    "        if self.transform is not None:\n",
    "            img_as_tensor = self.transform(single_image)\n",
    "        # Return image ONLY\n",
    "        return img_as_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_datasets(X_train, y_train, X_val = None, y_val = None, norm_params = None):\n",
    "\n",
    "        print(norm_params)\n",
    "        val_transforms = transforms. Compose([\n",
    "            transforms.Resize(size=(64, 64)),\n",
    "            # transforms.RandomCrop(64),\n",
    "#             transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=[norm_params['train_norm_mean']],\n",
    "#                         std =[norm_params['train_norm_std']])\n",
    "        ])\n",
    "\n",
    "        train_transforms = transforms. Compose([\n",
    "            transforms.Resize(size=(64, 64)),\n",
    "#             transforms.Grayscale(),\n",
    "            # transforms.resize(image, (64, 64)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=360),\n",
    "            # transforms.RandomAffine(16),\n",
    "            transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=[norm_params['train_norm_mean']],\n",
    "#                         std =[norm_params['train_norm_std']])\n",
    "        ])\n",
    "\n",
    "        train_dataset = ListsTrainDataset(X_train, y_train, transform = train_transforms)\n",
    "\n",
    "        if X_val is None and y_val is None:\n",
    "            return train_dataset\n",
    "\n",
    "        elif X_val is not None:\n",
    "            test_dataset = ListsTrainDataset(X_val, y_val, transform = val_transforms)\n",
    "        else:\n",
    "            test_dataset = ListsTestDataset(X_val, transform = test_transforms)\n",
    "\n",
    "        return (train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing during validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def apply_sobel(image):\n",
    "    kernel_vert = np.array([[1,0,-1], [2,0,-2], [1,0,-1]])\n",
    "    kernel_horz = np.array([[-1,-2,-1], [0,0,0], [1,2,1]])\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.filter2D(image, -1, kernel_vert)\n",
    "    image = cv2.filter2D(image, -1, kernel_horz)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def apply_gamma(image, gamma=0.5):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def apply_sobel(image):\n",
    "    kernel_vert = np.array([[1,0,-1], [2,0,-2], [1,0,-1]])\n",
    "    kernel_horz = np.array([[-1,-2,-1], [0,0,0], [1,2,1]])\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.filter2D(image, -1, kernel_vert)\n",
    "    image = cv2.filter2D(image, -1, kernel_horz)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def apply_gamma(image, gamma=0.5):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "\n",
    "def augment_and_transform_for_prediction(im):\n",
    "    \n",
    "    num_of_rotations = 5\n",
    "    \n",
    "    im = transforms.ToPILImage()(im.squeeze())\n",
    "    im = np.array(im)\n",
    "    \n",
    "    augmented_image_list = list()\n",
    "    augmented_image_list.append(im) ##original\n",
    "    ##augment\n",
    "    for i in range(num_of_rotations):\n",
    "        rotated = ndimage.rotate(im, np.random.randint(0, high = 360))\n",
    "        augmented_image_list.append(rotated)\n",
    "\n",
    "    ##Transformed\n",
    "\n",
    "    re_transform_for_cnn = transforms. Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize(size=(64, 64)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "    sobel_images = []\n",
    "    for im in augmented_image_list:\n",
    "        sobel_images.append(apply_gamma(im))\n",
    "        sobel_images.append(apply_sobel(im))\n",
    "\n",
    "    augmented_image_list.extend(sobel_images)\n",
    "\n",
    "    ##back to PIL and Torch Tensor\n",
    "\n",
    "    tensor_list = []\n",
    "    for im in augmented_image_list:\n",
    "        tensor_list.append(re_transform_for_cnn(im).unsqueeze(0))\n",
    "\n",
    "    final_tensor = torch.Tensor()\n",
    "    final_tensor.size()\n",
    "    for i, image in enumerate(tensor_list):\n",
    "        if i == 0:\n",
    "            final_tensor = tensor_list[i]\n",
    "        else:\n",
    "            final_tensor = torch.cat((final_tensor, image),0)\n",
    "#     print(final_tensor.size())\n",
    "    return final_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch, model, optimizer, scheduler, name = 'trained_model.pt'):\n",
    "    train_state = {\n",
    "    'epoch': epoch,\n",
    "    # 'model' : model,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'scheduler': scheduler.state_dict()\n",
    "    }\n",
    "    print(\"Saved model at: \"+str(name))\n",
    "    torch.save(train_state, 'models/'+str(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, test_loader,\n",
    "                       num_epochs, device = torch.device(\"cuda:0\"),\n",
    "                       learning_rate = 0.001,\n",
    "                       weight_decay = 0,\n",
    "                       multiGPU = False,\n",
    "                       save_name = 'trained_model.pt'):\n",
    "    batch_size = train_loader.batch_size\n",
    "    criterion = nn.CrossEntropyLoss();\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr = learning_rate,\n",
    "                                 weight_decay = weight_decay);\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate,\n",
    "    #                                 weight_decay = weight_decay,\n",
    "    #                                 momentum = 0.6);\n",
    "\n",
    "    patience = 15 if weight_decay > 0 else 10\n",
    "    step_size = 25 if weight_decay > 0 else 15\n",
    "\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'max', factor=0.1, patience=patience, verbose=True)\n",
    "    #Training\n",
    "    print(\"lr:{} wd:{}\".format(learning_rate, weight_decay))\n",
    "    model.train().to(device)\n",
    "#     if isinstance(model, EnsembleClassifier):\n",
    "#         if multiGPU == True:\n",
    "#             print(\"multiGPU\")\n",
    "#             model.set_devices_multiGPU()\n",
    "\n",
    "    history = {'batch': [], 'loss': [], 'accuracy': []}\n",
    "    best_val_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        # scheduler.step()\n",
    "        model.train()\n",
    "        tic=timeit.default_timer()\n",
    "        losses = [] #losses in epoch per batch\n",
    "        accuracies_train = [] #accuracies in epoch per batch\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).squeeze(1).long().to(device)#.cpu()\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "            _, argmax = torch.max(outputs, 1)\n",
    "            accuracy_train = (labels == argmax.squeeze()).float().mean()*100\n",
    "            accuracies_train.append(accuracy_train.cpu())\n",
    "            # Show progress\n",
    "            if (i+1) % 32 == 0:\n",
    "                log = \" \".join([\n",
    "                  \"Epoch : %d/%d\" % (epoch+1, num_epochs),\n",
    "                  \"Iter : %d/%d\" % (i+1, len(train_loader.dataset)//batch_size)])\n",
    "                print('\\r{}'.format(log), end=\" \")\n",
    "\n",
    "        epoch_log = \" \".join([\n",
    "          \"Epoch : %d/%d\" % (epoch+1, num_epochs),\n",
    "          \"Training Loss: %.4f\" % np.mean(losses),\n",
    "          \"Training Accuracy: %.4f\" % np.mean(accuracies_train)])\n",
    "        print('\\r{}'.format(epoch_log))\n",
    "\n",
    "        ##VALIDATION SCORE AFTER EVERY EPOCH\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        total_labels = torch.Tensor().long()\n",
    "        total_predicted = torch.Tensor().long()\n",
    "\n",
    "        for images, labels in test_loader:\n",
    "            augmented_images = augment_and_transform_for_prediction(images)\n",
    "            augmented_images = Variable(augmented_images).to(device)\n",
    "            labels = labels.squeeze(1)\n",
    "            outputs = model(augmented_images)\n",
    "            \n",
    "            probabilities = torch.exp(nn.LogSoftmax()(outputs))\n",
    "            predicted = torch.argmax(torch.mean(probabilities, 0))\n",
    "\n",
    "#             print(predicted)\n",
    "#             print(labels)\n",
    "            total += labels.size(0)\n",
    "        #     print(total)\n",
    "            correct += (predicted.cpu().long() == labels).sum()\n",
    "            total_labels = torch.cat((total_labels,labels))\n",
    "            total_predicted = torch.cat((total_predicted, predicted.cpu().long().unsqueeze(dim=0)))\n",
    "            val_accuracy = 100*correct.item() / total\n",
    "        print('VALIDATION SET ACCURACY: %.4f %%' % val_accuracy)\n",
    "        scheduler.step(correct.item() / total)\n",
    "\n",
    "        ###Results for analysis###\n",
    "        if val_accuracy >= best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            save_model(epoch, model, optimizer, scheduler, name = save_name)\n",
    "            pickle.dump(total_predicted.cpu().long(), open(\"test_predicted.pkl\", \"wb\"))\n",
    "            pickle.dump(total_labels.long(), open(\"test_labels.pkl\", \"wb\"))\n",
    "\n",
    "        toc=timeit.default_timer()\n",
    "        if epoch+1 == 70:\n",
    "            for group in optimizer.param_groups:\n",
    "                if 'lr' in group.keys():\n",
    "                    if group['lr'] == 0.001:\n",
    "                        group['lr'] == 0.0001\n",
    "                        scheduler._reset()\n",
    "                        print(\"MANUAL CHANGE OF LR\")\n",
    "        print(toc-tic)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Device selection and CNN\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "if torch.cuda.device_count()>1:\n",
    "    device = torch.device(\"cuda:1\") #Multi-GPU\n",
    "elif torch.cuda.device_count()>0:\n",
    "    device = torch.device(\"cuda:0\") #Single-GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\") #No-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "lr:0.0001 wd:0\n",
      "Epoch : 1/30 Training Loss: 0.9315 Training Accuracy: 60.9645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimtsi/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET ACCURACY: 63.2219 %\n",
      "Saved model at: trained_model.pt\n",
      "29.605181795000135\n",
      "Epoch : 2/30 Training Loss: 0.6998 Training Accuracy: 71.5429\n",
      "VALIDATION SET ACCURACY: 79.3313 %\n",
      "Saved model at: trained_model.pt\n",
      "31.225390825999966\n",
      "Epoch : 3/30 Training Loss: 0.6376 Training Accuracy: 74.6367\n",
      "VALIDATION SET ACCURACY: 45.2888 %\n",
      "35.17273220300012\n",
      "Epoch : 4/30 Training Loss: 0.5831 Training Accuracy: 76.7768\n",
      "VALIDATION SET ACCURACY: 86.3222 %\n",
      "Saved model at: trained_model.pt\n",
      "32.64989695500026\n",
      "Epoch : 5/30 Training Loss: 0.5561 Training Accuracy: 78.0909\n",
      "VALIDATION SET ACCURACY: 75.0760 %\n",
      "36.21423732399944\n",
      "Epoch : 6/30 Training Loss: 0.5228 Training Accuracy: 79.0446\n",
      "VALIDATION SET ACCURACY: 80.5471 %\n",
      "34.00857068700043\n",
      "Epoch : 7/30 Training Loss: 0.4945 Training Accuracy: 79.8280\n",
      "VALIDATION SET ACCURACY: 82.3708 %\n",
      "34.55536694300008\n",
      "Epoch : 8/30 Training Loss: 0.4806 Training Accuracy: 80.7561\n",
      "VALIDATION SET ACCURACY: 81.4590 %\n",
      "34.57634541799962\n",
      "Epoch : 9/30 Training Loss: 0.4662 Training Accuracy: 81.1393\n",
      "VALIDATION SET ACCURACY: 80.5471 %\n",
      "35.25133730200014\n",
      "Epoch : 10/30 Training Loss: 0.4575 Training Accuracy: 81.2443\n",
      "VALIDATION SET ACCURACY: 74.4681 %\n",
      "34.90012982799999\n",
      "Epoch : 11/30 Training Loss: 0.4344 Training Accuracy: 82.1327\n",
      "VALIDATION SET ACCURACY: 79.3313 %\n",
      "35.76178994699967\n",
      "Epoch : 12/30 Training Loss: 0.4316 Training Accuracy: 82.5414\n",
      "VALIDATION SET ACCURACY: 83.2827 %\n",
      "35.01633631800087\n",
      "Epoch : 13/30 Training Loss: 0.4130 Training Accuracy: 83.0523\n",
      "VALIDATION SET ACCURACY: 83.8906 %\n",
      "37.94539696299944\n",
      "Epoch : 14/30 Training Loss: 0.4145 Training Accuracy: 82.6777\n",
      "VALIDATION SET ACCURACY: 61.3982 %\n",
      "36.39388194900039\n",
      "Epoch : 15/30 Training Loss: 0.3974 Training Accuracy: 83.8584\n",
      "VALIDATION SET ACCURACY: 62.6140 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-05.\n",
      "36.665707785999984\n",
      "Epoch : 16/30 Training Loss: 0.3504 Training Accuracy: 85.2435\n",
      "VALIDATION SET ACCURACY: 72.6444 %\n",
      "35.60125009500007\n",
      "Epoch : 17/30 Training Loss: 0.3359 Training Accuracy: 85.7090\n",
      "VALIDATION SET ACCURACY: 80.5471 %\n",
      "37.91648210599942\n",
      "Epoch : 18/30 Training Loss: 0.3217 Training Accuracy: 86.7251\n",
      "VALIDATION SET ACCURACY: 74.1641 %\n",
      "38.3080546580004\n",
      "Epoch : 19/30 Training Loss: 0.3288 Training Accuracy: 86.1830\n",
      "VALIDATION SET ACCURACY: 77.2036 %\n",
      "40.79563719899943\n",
      "Epoch : 20/30 Training Loss: 0.3201 Training Accuracy: 86.9267\n",
      "VALIDATION SET ACCURACY: 61.7021 %\n",
      "49.396628616999806\n",
      "Epoch : 21/30 Training Loss: 0.3123 Training Accuracy: 86.9550\n",
      "VALIDATION SET ACCURACY: 69.9088 %\n",
      "50.83942512499925\n",
      "Epoch : 22/30 Training Loss: 0.3149 Training Accuracy: 87.1651\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c40b0ca9812f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                    \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                    \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                    save_name = 'trained_model.pt')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-fc14e1ba3ecf>\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, test_loader, num_epochs, device, learning_rate, weight_decay, multiGPU, save_name)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0maugmented_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_and_transform_for_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0maugmented_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-186e61753a1b>\u001b[0m in \u001b[0;36maugment_and_transform_for_prediction\u001b[0;34m(im)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maugmented_image_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0msobel_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_gamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msobel_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_sobel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0maugmented_image_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msobel_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c5ff36d25009>\u001b[0m in \u001b[0;36mapply_sobel\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_sobel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mkernel_vert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mkernel_horz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##=============TRAIN==============##\n",
    "from torchvision.models.resnet import Bottleneck\n",
    "import NNs\n",
    "from NNs import *\n",
    "importlib.reload(NNs)\n",
    "\n",
    "#datasets/dataloaders\n",
    "train_dataset, test_dataset = create_train_val_datasets(X_train, Y_train,\n",
    "                                                       test_PIL_images, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32,\n",
    "    shuffle = True, num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                            batch_size = 1, shuffle = False)\n",
    "\n",
    "#CNN initialization and training\n",
    "\n",
    "\n",
    "cnn = ResNetDynamic(Bottleneck, [3, 4, 6, 3],\n",
    "            num_layers = 2, pretrained_nn = None)\n",
    "\n",
    "trained_model = train_and_validate(cnn, train_loader, test_loader,\n",
    "                                   num_epochs=30,\n",
    "                                   learning_rate = 0.0001,\n",
    "                                   weight_decay = 0,\n",
    "                                   device = device,\n",
    "                                   save_name = 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##=============TRAIN==============##\n",
    "from torchvision.models.resnet import Bottleneck\n",
    "import NNs\n",
    "from NNs import *\n",
    "importlib.reload(NNs)\n",
    "\n",
    "#datasets/dataloaders\n",
    "train_dataset, test_dataset = create_train_val_datasets(X_train, Y_train,\n",
    "                                                       test_PIL_images, test_labels)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                            batch_size = 1, shuffle = False)\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best_model = cnn\n",
    "# best_model.load_state_dict(torch.load('models/trained_model.pt')['state_dict'])\n",
    "\n",
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# total_labels = torch.Tensor().long()\n",
    "# total_predicted = torch.Tensor().long()\n",
    "\n",
    "# for idx, (images, labels) in enumerate(test_loader):\n",
    "#     augmented_images = augment_and_transform_for_prediction(images)\n",
    "#     augmented_images = Variable(augmented_images).to(device)\n",
    "#     labels = labels.squeeze(1)\n",
    "#     outputs = best_model(augmented_images)\n",
    "#     predicted = torch.argmax(torch.mean(outputs, 0))\n",
    "#     total += labels.size(0)\n",
    "# #     print(total)\n",
    "#     correct += (predicted.cpu().long() == labels).sum()\n",
    "# #     print(correct)\n",
    "    \n",
    "#     total_labels = torch.cat((total_labels,labels))\n",
    "#     total_predicted = torch.cat((total_predicted, predicted.cpu().long().unsqueeze(dim = 0)))\n",
    "\n",
    "#     val_accuracy = 100*correct.item() / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = cnn\n",
    "# best_model.load_state_dict(torch.load('models/trained_model.pt')['state_dict'])\n",
    "\n",
    "# trained_model = train_and_validate(best_model, train_loader, test_loader,\n",
    "#                                    num_epochs=30,\n",
    "#                                    learning_rate = 0.0001,\n",
    "#                                    weight_decay = 0,\n",
    "#                                    device = device,\n",
    "#                                    save_name = 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pickle.load(open(\"test_predicted.pkl\", \"rb\"))\n",
    "test_labels_real = pickle.load(open(\"test_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  prediction\n",
       "0        3           3\n",
       "1        2           3\n",
       "2        3           3\n",
       "3        3           3\n",
       "4        0           0\n",
       "5        3           3\n",
       "6        3           3\n",
       "7        0           0\n",
       "8        3           3\n",
       "9        2           3\n",
       "10       3           0\n",
       "11       3           3\n",
       "12       3           3\n",
       "13       3           3\n",
       "14       3           2\n",
       "15       3           3\n",
       "16       0           0\n",
       "17       3           0\n",
       "18       3           3\n",
       "19       3           3\n",
       "20       0           0\n",
       "21       3           3\n",
       "22       3           4\n",
       "23       0           0\n",
       "24       3           3\n",
       "25       0           0\n",
       "26       3           3\n",
       "27       3           3\n",
       "28       3           3\n",
       "29       0           0\n",
       "..     ...         ...\n",
       "299      3           3\n",
       "300      0           0\n",
       "301      0           0\n",
       "302      3           1\n",
       "303      3           3\n",
       "304      3           3\n",
       "305      3           3\n",
       "306      3           2\n",
       "307      3           3\n",
       "308      3           3\n",
       "309      3           3\n",
       "310      3           3\n",
       "311      0           0\n",
       "312      3           3\n",
       "313      3           3\n",
       "314      0           0\n",
       "315      0           0\n",
       "316      3           3\n",
       "317      3           3\n",
       "318      0           0\n",
       "319      3           3\n",
       "320      3           3\n",
       "321      3           4\n",
       "322      3           3\n",
       "323      0           0\n",
       "324      3           3\n",
       "325      3           3\n",
       "326      0           0\n",
       "327      3           3\n",
       "328      3           3\n",
       "\n",
       "[329 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict({'label' : test_labels, 'prediction' :predicted })\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Class': 3, 'Total': 220, 'Correct': 197, 'Accuracy': 0.8954545454545455}\n",
      "{'Class': 2, 'Total': 8, 'Correct': 0, 'Accuracy': 0.0}\n",
      "{'Class': 0, 'Total': 83, 'Correct': 81, 'Accuracy': 0.9759036144578314}\n",
      "{'Class': 4, 'Total': 7, 'Correct': 5, 'Accuracy': 0.7142857142857143}\n",
      "{'Class': 1, 'Total': 11, 'Correct': 1, 'Accuracy': 0.09090909090909091}\n"
     ]
    }
   ],
   "source": [
    "## per class accuracy\n",
    "class_df = pd.DataFrame()\n",
    "for cl in results_df['label'].unique():\n",
    "    unique_df = results_df.loc[results_df['label'] == cl]\n",
    "    correct = len(unique_df.loc[unique_df['prediction'] == cl])\n",
    "    total = len(unique_df)\n",
    "    acc = correct/total\n",
    "    results_dict = {'Class' : cl , 'Total' : total, 'Correct' : correct, 'Accuracy' : acc}\n",
    "    print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diagnosis(x):\n",
    "    if x == 0 or x == 1: ##white_blood or debris\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "        \n",
    "actual_infection = results_df.label.apply(lambda s: pd.Series({'infection': create_diagnosis(s)}))\n",
    "predicted_infection = results_df.prediction.apply(lambda s: pd.Series({'pred_infection': create_diagnosis(s)}))\n",
    "\n",
    "\n",
    "\n",
    "final = pd.concat([results_df, actual_infection, predicted_infection], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    221\n",
       "0    108\n",
       "Name: pred_infection, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.pred_infection.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4, 18, 217)\n"
     ]
    }
   ],
   "source": [
    "print((TN, FP, FN, TP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90   4]\n",
      " [ 18 217]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cf = confusion_matrix(final.infection, final.pred_infection)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9819004524886877, sensitivity: 0.9234042553191489, specificity: 0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = cf.ravel()\n",
    "\n",
    "sensitivity = TP/(TP+FN)\n",
    "specificity = TN/(TN+FP)\n",
    "precision = TP/(TP+FP)\n",
    "print('precision: {}, sensitivity: {}, specificity: {}'.format(precision, sensitivity, specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = Image.open('split/train/ovale_3243.png')\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import scipy.misc\n",
    "\n",
    "# new = apply_sobel(np.array(im))\n",
    "# new = apply_gamma(new)\n",
    "\n",
    "# # scipy.misc.imsave('im.png', new)\n",
    "# plt.imshow(new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
